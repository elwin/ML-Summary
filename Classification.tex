\section*{Classification}

Solve $w^* = \underset{w}{\operatorname{argmin}} ~ l(w;x_i,y_i)$, $l$ ...loss function

\subsection*{0/1 loss (not convex / not diff)}
$l_{0/1} (w;y_i,x_i) = 1 \text{ if } y_i \neq \operatorname{sign}(w^Tx_i) \text{ else } 0$

\subsection*{Perceptron (convex / not diff)}
Gradient is informative\\
Use $l_P (w;y_i,x_i) = \operatorname{max}(0, -y_i w^T x_i)$ and SGD\\
$\nabla_w l_P(w;y_i,x_i) = 
\begin{cases}
    0 &\text{if } y_i w^T x_i \geq 0\\
    -y_i x_i &\text{otherwise}
\end{cases}$ \\
Data lin. separable $\Rightarrow$ obtains a lin. separator

\subsection*{Support Vector Machine (SVM)}
Hinge loss: $l_H(w;x_i,y_i) = \operatorname{max}(0,1-y_i w^T x_i)$ \\
$\nabla_w l_H(w;y,x) = 
\begin{cases}
    0 &\text{if } _i w^T x_i \geq 1\\
    -y_i x_i &\text{otherwise}
\end{cases}$\\
$w^* = \underset{w}{\operatorname{argmin}} ~ \frac{1}{n} \sum_{i=1}^n l_H(w;x_i,y_i) + \lambda||w||_2^2$\\ For L1-SVM (feature selection) use $||w||_1$ 

\subsection*{Multiple classes}
One-vs-all: $c$ classifiers, could lead to class imbalance, might not be linearly seperable\\
One-vs-one: $\frac{c(c-1)}{2}$ classifiers

\subsection*{Overview}
SVM: Maximum margin around separator\\
Perceptron: Doesn't care about margin\\
Logistic Regression: Weighted\\
NN: Smooth (e.g. Tanh) or sharp (e.g. ReLU)